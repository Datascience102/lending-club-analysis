---
title: "LendingClubAnalysis"
author: "Steve Isaacs, Kailing See, Sally Guo, Cristian Benavides"
date: "1/12/2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# In order to install ggthemr, you have to load devtools and install it from github. For me (OBoulant), this command did not worked
install.packages("ggthemr")
install.packages("knitr")
install.packages("rpart")
install.packages("corrplot")
install.packages("rpart.plot")
install.packages("fastICA")
install.packages("FactoMineR")

library("ggthemr")
library("knitr")
library("rpart")
library("corrplot")
library(reshape2)
library(rpart.plot)
library(caret)
library(FactoMineR)
library(fastICA)
```

Business Problem: Assessing credit worthiness of customers in Lending Club and their probability of defaulting.

Data set: https://www.kaggle.com/wendykan/lending-club-loan-data

### 1.Introduction to the Business Problem

Lending Club is the world’s largest online marketplace connecting borrowers and investors.They operate at a lower cost than traditional bank lending programs and pass the savings on to borrowers in the form of lower rates and to investors in the form of solid returns.
Source: https://www.lendingclub.com/

This project aims to analyse Lending Club's issued loans over a 9 year period (2007-2015) and identify early indicators that could predict a customer's probability of defaulting. The insight obtained could help to drive differentiated credit approval processes for different customer segments (e.g faster approval time, minimal security for low risk customers).

### 2.Process to solve the Business Problem

We would suggest the following process:      
1. Understand Lending Club Business Model & Data Set    
2. Clean the data, identify relevant attributes/columns & separate training and testing dataset    
3. Generate Hypothesis    
4. Apply Dimensionality Reduction on Hypothesis     
5. Apply Segmentation & Classification Tree on Training Dataset    
6. Apply Algorithm on Testing Dataset (Iterate if required)    
7. Capture insights & Summarise    

**OBoulant comments :**
If you want to "identify early indicators that could predict a customer’s probability of defaulting", you have to identify into the dataset, a column that would "represent" the "customer’s probability of defaulting". 
--> Do you have an idea of which column within the data could play this role? ProjectData$loan_status

### 3.Key Summary of Data

```{r eval = FALSE, echo=FALSE, comment=NA, warning=FALSE, message=FALSE,results='markup'}
ProjectData<- read.csv(file = "Data/loan.csv", header = TRUE, sep=",", stringsAsFactors = FALSE, nrows=500000)
# OBoulant : i added the "stringsAsFactors = FALSE", because I want to look at the variables represented by character strings
# SIsaacs: I added "nrows = 10000" to work with a smaller more manageable data set
# print(colnames(ProjectData))
# summary(ProjectData)

# Keep only observations for which 'loan_status' is in ('Charged Off', 'Current', 'Fully Paid')
ProjectData <- ProjectData[ ProjectData$loan_status %in% c('Charged Off', 'Current', 'Fully Paid'), ]

# Take for now only numerical values
ProjectDataClean2 <- ProjectData[, c('id', 'loan_amnt', 'annual_inc', 'pub_rec', 'open_acc', 'delinq_2yrs', 'int_rate')]
colnames(ProjectDataClean2) <- c('ID', 'LoanAmount', 'AnnualIncome', 'PublicRecords', 'NumberCreditLines', 'DelinquencyPrior2Years', 'InterestRate')

## Handle LoanStatus
ProjectDataClean2 <- cbind(ProjectDataClean2, 
                          data.frame(predict(dummyVars(~ loan_status, data = ProjectData),
                                                    newdata = ProjectData)))
# remove columns 'loan_statusCurrent' and 'loan_statusFully.Paid'. Why ? Because you only need loan_statusCharged.Off
ProjectDataClean2 <- ProjectDataClean2[, !(names(ProjectDataClean2) %in% c('loan_statusCurrent', 'loan_statusFully.Paid'))]

## Handle LoanTerm
ProjectDataClean2$LoanTerm <- 0
ProjectDataClean2[ProjectData$term == " 36 months", c('LoanTerm')] <- 36
ProjectDataClean2[ProjectData$term == " 60 months", c('LoanTerm')] <- 60

## Handle EmploymentLength
ProjectDataClean2$EmploymentLength <- 0
ProjectDataClean2[ProjectData$emp_length == "< 1 year", c('EmploymentLength')] <- 0
ProjectDataClean2[ProjectData$emp_length == "1 year", c('EmploymentLength')] <- 1
ProjectDataClean2[ProjectData$emp_length == "2 years", c('EmploymentLength')] <- 2
ProjectDataClean2[ProjectData$emp_length == "3 years", c('EmploymentLength')] <- 3
ProjectDataClean2[ProjectData$emp_length == "4 years", c('EmploymentLength')] <- 4
ProjectDataClean2[ProjectData$emp_length == "5 years", c('EmploymentLength')] <- 5
ProjectDataClean2[ProjectData$emp_length == "6 years", c('EmploymentLength')] <- 6
ProjectDataClean2[ProjectData$emp_length == "7 years", c('EmploymentLength')] <- 7
ProjectDataClean2[ProjectData$emp_length == "8 years", c('EmploymentLength')] <- 8
ProjectDataClean2[ProjectData$emp_length == "9 years", c('EmploymentLength')] <- 9
ProjectDataClean2[ProjectData$emp_length == "10+ years", c('EmploymentLength')] <- 10
ProjectDataClean2[ProjectData$emp_length == "n/a", c('EmploymentLength')] <- NA

## Handle LoanGrade
ProjectDataClean2 <- cbind(ProjectDataClean2, 
                          data.frame(predict(dummyVars(~ grade, data = ProjectData),
                                                    newdata = ProjectData)))

#remove NAs
ProjectDataNumeric<-na.omit(ProjectDataClean2)

#correlation matrix to explore data
acor <- cor(ProjectDataNumeric)
corrplot(acor, type="lower", tl.srt=45)

```
       
```{r eval = FALSE, echo=FALSE, comment=NA, warning=FALSE, message=FALSE,results='markup'}
# OBoulant comments :
######################

# You should decide what you want to do with categorical variables
# 2017/01/24 : I removed from the list the variables you handled above
######################################################################

## 3 - sub_grade
unique(ProjectData$sub_grade)
ProjectData$sub_grade <- as.factor(ProjectData$sub_grade)
## 4 - emp_title
unique(ProjectData$emp_title)
head(table(ProjectData$emp_title))
sum(ProjectData$emp_title == '') # Many blanks !
# This field should be re-processed
## 6 - home_ownership
unique(ProjectData$home_ownership)
ProjectData$home_ownership <- as.factor(ProjectData$home_ownership)
## 7 - verification_status
unique(ProjectData$verification_status)
ProjectData$verification_status <- as.factor(ProjectData$verification_status)
## 8 - issue_d
unique(ProjectData$issue_d)
ProjectData$issue_d <- as.factor(ProjectData$issue_d)
# Maybe should be separated in issue_year and issue_month
## 10 - pymnt_plan
unique(ProjectData$pymnt_plan)
ProjectData$pymnt_plan <- as.factor(ProjectData$pymnt_plan)
## 11 - url
unique(ProjectData$url) # Too many modalities, keep it in character strings - Not to be used !
## 12 - desc
unique(ProjectData$desc) # Too many modalities, keep it in character strings - Not to be used !
## 13 - purpose 
unique(ProjectData$purpose)
ProjectData$purpose <- as.factor(ProjectData$purpose)
## 14 - title
unique(ProjectData$title)
# Either should be re-processed or not to be used ! Or do a word count, i don't know
## 15 - zip_code
unique(ProjectData$zip_code)
ProjectData$zip_code <- as.factor(ProjectData$zip_code)
## 16 - addr_state
unique(ProjectData$addr_state)
ProjectData$addr_state <- as.factor(ProjectData$addr_state)
## 17 - earliest_cr_line
unique(ProjectData$earliest_cr_line)
# Some missing Data
# Maybe should be separated into earliest_cr_line_month and earliest_cr_line_year
ProjectData$earliest_cr_line <- as.factor(ProjectData$earliest_cr_line)
## 18 - initial_list_status
unique(ProjectData$initial_list_status)
ProjectData$initial_list_status <- as.factor(ProjectData$initial_list_status)
## 19 - last_pymnt_d
unique(ProjectData$last_pymnt_d)
ProjectData$last_pymnt_d <- as.factor(ProjectData$last_pymnt_d)
# Some missing Data
# Maybe should be separated into last_pymnt_month and last_pymnt_year
## 20 - next_pymnt_d
unique(ProjectData$next_pymnt_d)
# Some missing Data
# Maybe should be separated into next_pymnt_month and next_pymnt_year
ProjectData$next_pymnt_d <- as.factor(ProjectData$next_pymnt_d)
# 21 - last_credit_pull_d
unique(ProjectData$last_credit_pull_d)
# Some missing Data
# Maybe should be separated into last_credit_pull_month and last_credit_pull_year
ProjectData$last_credit_pull_d <- as.factor(ProjectData$last_credit_pull_d)
# 22 - application_type
unique(ProjectData$application_type)
ProjectData$application_type <- as.factor(ProjectData$application_type)
# 23 - verification_status_joint
unique(ProjectData$verification_status_joint)
ProjectData$verification_status_joint <- as.factor(ProjectData$verification_status_joint)

# Result Dataset
summary(ProjectData)

```

### 4.Dimensionality Reduction

```{r eval = FALSE, echo=FALSE, comment=NA, warning=FALSE, message=FALSE,results='markup'}

ProjectDataNumericWithoutStatus <- ProjectDataNumeric[, -which(names(ProjectDataNumeric) %in% c('loan_statusCharged.Off'))]
res.pca = PCA(ProjectDataNumericWithoutStatus, scale.unit=TRUE, ncp=5)

# Information embedded by principal components
barplot(res.pca$eig[,2])

```

```{r eval = FALSE, echo=FALSE, comment=NA, warning=FALSE, message=FALSE,results='markup'}

# How the 2 first principal components are constructed by the original variables
plot(res.pca,choix="var",axes=c(1,2))

```

```{r eval = FALSE, echo=FALSE, comment=NA, warning=FALSE, message=FALSE,results='markup'}

# How the 2 first principal components are constructed by the original variables
print(res.pca$var$coord)

```


### 5.Clustering and Segmentation

### 6. Results 

>>>>>>> 7664b6275553d5ba40165c41ff18eb644596ceb4
